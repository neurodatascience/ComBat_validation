{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "df0c8e08-65ba-42d8-a346-123c9167306c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#site i, #participant j, feature g\n",
    "\n",
    "from spicy import stats\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "#######\n",
    "# from sklearn.neural_network import MLPClassifier\n",
    "import torch\n",
    "import torch.nn as nnv\n",
    "# import torch.optim as optim\n",
    "##########\n",
    "np.random.seed(666)\n",
    "#Total sample size (sum of all sites) is 5000\n",
    "N=500\n",
    "#the number of features is 1000.\n",
    "G=10\n",
    "#10 sites\n",
    "I=10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "744370a6-6214-4a9c-91da-7e1759a26efb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tau_i is finite.\n",
      "gamma_ig is finite\n",
      "delta_ig is finite\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "#This section will be the same for both the homogeneous and heterogeneous versions.\n",
    "#for homogenous version, we have the same number of samples in each site\n",
    "n_i=int(N/I)\n",
    "n_samples=[n_i for _ in range(I)]\n",
    "###\n",
    "alpha_G = np.random.uniform(0, 0.5,G)\n",
    "\n",
    "Y_I=np.random.uniform(0,0.1,I)\n",
    "tau_I=stats.invgamma.rvs(a=2, scale=0.5,size=I)\n",
    "\n",
    "df = pd.DataFrame({'Y_i': Y_I, 'tau_i': tau_I})\n",
    "gamma_IG=df.apply(lambda x: stats.norm.rvs(loc=x['Y_i'], scale=np.sqrt(x['tau_i']), size=G), axis=1)\n",
    "\n",
    "lambda_I=stats.gamma.rvs(a=50,scale=50,size=I)\n",
    "v_I=stats.gamma.rvs(a=50,scale=1,size=I)\n",
    "df1=pd.DataFrame({'lambda_i':lambda_I,'v_i':v_I})\n",
    "delta_IG=df1.apply(lambda x:stats.gamma.rvs(a=x['lambda_i']*x['v_i'],scale=x['v_i'],size=G),axis=1)\n",
    "\n",
    "sigma_G=stats.halfcauchy.rvs(scale=0.2, size=G)\n",
    "\n",
    "#####################################################################################################\n",
    "#check for finite value\n",
    "# print(\"tau_i:\", tau_i)\n",
    "# print(\"gamma_ig:\", gamma_ig)\n",
    "# print(\"delta_ig:\", delta_ig)\n",
    "\n",
    "def check_finite_array(arr, name):\n",
    "    if not np.isfinite(arr).all():\n",
    "        print(f\"Warning: {name} contains inf or NaN!\")\n",
    "    else:\n",
    "        print(f\"{name} is finite.\")\n",
    "\n",
    "def check_finite_series(series, name):\n",
    "    for idx, row in series.items():\n",
    "        if not np.isfinite(row).all():\n",
    "            print(f\"Warning: {name}[{idx}] contains inf or NaN!\")\n",
    "    else:\n",
    "        print(f'{name} is finite')\n",
    "\n",
    "check_finite_array(tau_I, \"tau_i\")\n",
    "check_finite_series(gamma_IG, \"gamma_ig\")\n",
    "check_finite_series(delta_IG, \"delta_ig\")\n",
    "print('done')\n",
    "######################################################################################################\n",
    "\n",
    "#fixed effects of age and sex, different for different features\n",
    "theta_age=stats.norm.rvs(loc=0,scale=1,size=G)\n",
    "theta_sex=stats.norm.rvs(loc=0,scale=1,size=G)\n",
    "theta_G=pd.DataFrame({\"age\":theta_age,\"sex\":theta_sex})\n",
    "# print(theta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "8e760566-a2ce-43bd-82d5-d1961334124e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50\n",
      "50\n",
      "50\n",
      "50\n",
      "50\n",
      "50\n",
      "50\n",
      "50\n",
      "50\n",
      "50\n"
     ]
    }
   ],
   "source": [
    "sex=[]#it is a list with 10 entries, where each entry contains generated data for one site\n",
    "age=[]#it is a list with 10 entries, where each entry contains generated data for one site\n",
    "\n",
    "for n in n_samples:\n",
    "    #covariates sex\n",
    "    #for site i with n_i samples, the probability of male is equal to female as 50%.\n",
    "    v1=np.random.binomial(n=1, p=0.5, size=n)\n",
    "    sex.append(v1)\n",
    "    #covariate age\n",
    "    #by reading the median of all boxplots, I guess the mean to be 40 and 10 for sd.\n",
    "    v2=stats.norm.rvs(loc=40, scale=10, size=n)\n",
    "    v2 = v2[v2 > 0]\n",
    "    print(len(v2))\n",
    "    while len(v2) < n:\n",
    "        additional_samples = stats.norm.rvs(loc=40, scale=10, size=n - len(v2))\n",
    "        v2 = np.concatenate((v2, additional_samples[additional_samples > 0]))\n",
    "    age.append(v2)\n",
    "\n",
    "#need to be standardized within site\n",
    "standardized_age = [(a - np.mean(a)) / np.std(a) for a in age]\n",
    "\n",
    "#no need to standardize sex as it is 0 or 1\n",
    "# print(sex[0].shape)\n",
    "# print(age[0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "29779405-dc10-4a19-b716-d38083802822",
   "metadata": {},
   "outputs": [],
   "source": [
    "#fixed effect transform function\n",
    "def fixed_effect_linear(x, theta):  # x: 2x1 and theta: 2x1\n",
    "    return np.dot(x.T, theta)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "7a64b852-ee70-4193-98f4-92125a0eb306",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         feature0      feature1       feature2      feature3      feature4  \\\n",
      "0   -1.833502e+06 -1.592200e+07   64230.566340 -1.062412e+06  4.847096e+05   \n",
      "1    6.835585e+04  5.927245e+06  -61939.625548 -4.241112e+06  5.160394e+05   \n",
      "2   -2.070052e+06  6.381244e+05  133711.407945  6.219031e+05 -1.012306e+05   \n",
      "3   -1.691034e+05  1.046735e+07  214768.755691 -3.453047e+05  2.413620e+05   \n",
      "4   -5.179555e+05  4.203051e+06  402667.583860  1.639996e+05  5.704886e+05   \n",
      "..            ...           ...            ...           ...           ...   \n",
      "495 -1.295978e+05 -3.727192e+06  -23265.615661 -1.423903e+06  1.049783e+05   \n",
      "496  1.485251e+05  2.754234e+06 -233875.877219  1.077260e+05  1.265957e+06   \n",
      "497  3.838380e+05  6.218149e+06 -160242.827068  4.267388e+05  9.803067e+05   \n",
      "498  5.852227e+05 -2.758260e+06 -386131.235137  3.048058e+06  1.362252e+05   \n",
      "499  6.219042e+05  2.975229e+06 -360834.381083  3.367052e+06 -6.663439e+05   \n",
      "\n",
      "         feature5      feature6      feature7      feature8      feature9  \\\n",
      "0   -1.822493e+05 -6.684748e+05  2.254018e+06 -2.096213e+06  4.715910e+06   \n",
      "1    1.466354e+07 -5.398303e+05 -5.345134e+05 -5.850942e+06  9.790154e+05   \n",
      "2   -1.688371e+06 -6.803304e+05  5.307365e+05 -1.883602e+06 -6.461247e+06   \n",
      "3   -7.925812e+06 -6.228591e+05  2.983843e+05 -4.794427e+06  1.371313e+07   \n",
      "4   -4.586184e+06  1.204444e+06  6.854189e+04  2.490930e+06 -3.391489e+06   \n",
      "..            ...           ...           ...           ...           ...   \n",
      "495 -9.876274e+06 -9.629037e+04  4.050165e+05  2.017455e+06 -3.760378e+06   \n",
      "496 -3.235483e+06 -5.582465e+05  7.132759e+05 -2.023949e+06  5.351141e+05   \n",
      "497  1.004503e+07 -2.837828e+05 -1.305464e+06 -3.213413e+06  2.078016e+06   \n",
      "498  1.146354e+07 -4.742832e+05  5.639450e+05  2.362784e+06  2.928329e+06   \n",
      "499 -5.136576e+06 -4.724026e+05 -1.931513e+06 -3.882752e+06  7.399844e+06   \n",
      "\n",
      "     site  \n",
      "0       0  \n",
      "1       0  \n",
      "2       0  \n",
      "3       0  \n",
      "4       0  \n",
      "..    ...  \n",
      "495     9  \n",
      "496     9  \n",
      "497     9  \n",
      "498     9  \n",
      "499     9  \n",
      "\n",
      "[500 rows x 11 columns]\n"
     ]
    }
   ],
   "source": [
    "#simulate features for all sites when assuming linear for fixed effect\n",
    "data = []\n",
    "for i in range(I):#for each site\n",
    "    J = n_i  # n_i is same for all sites\n",
    "    gamma_i = gamma_IG[i]\n",
    "    delta_i = delta_IG[i]    \n",
    "    x = pd.DataFrame({'age': standardized_age[i], 'sex': sex[i]})  # Ensure age[i] and sex[i] are iterable\n",
    "    \n",
    "    data1 = []\n",
    "    for j in range(J):#for each participant\n",
    "        each_participant = []  # generated features for each participant\n",
    "        x_ij = x.iloc[j, :]\n",
    "\n",
    "        for g in range(G):#for each feature\n",
    "            sigma_g = sigma_G[g]\n",
    "            theta_g = theta_G.iloc[g, :]\n",
    "            epsilon_ijg = stats.norm.rvs(loc=0, scale=sigma_g, size=1)[0]  \n",
    "            \n",
    "            phi = fixed_effect_linear(x_ij, theta_g)\n",
    "            y_ijg = alpha_G[g] + phi + gamma_i[g] + delta_i[g] * epsilon_ijg\n",
    "\n",
    "            each_participant.append(y_ijg)\n",
    "\n",
    "        data1.append(each_participant)\n",
    "\n",
    "    data1 = pd.DataFrame(data1, columns=[f'feature{g}' for g in range(G)])\n",
    "    data1['site'] = i\n",
    "    data.append(data1)\n",
    "\n",
    "final_data = pd.concat(data, ignore_index=True)\n",
    "print(final_data)\n",
    "#this simulated feature values are assumed to be value after standardization\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "6e6955ba-92d4-4a6b-acc8-5f7ed74cd676",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         feature0      feature1       feature2      feature3      feature4  \\\n",
      "0    2.564527e+05 -2.385620e+05 -163421.979171 -3.701143e+06  3.347463e+05   \n",
      "1   -1.980927e+05 -1.955470e+06  293476.945080 -6.426854e+06 -6.588653e+05   \n",
      "2   -2.910220e+05  5.299499e+06  447974.901065  4.589916e+06  6.107997e+04   \n",
      "3   -9.756237e+05  8.804577e+06   27943.500108 -7.771699e+05  3.608159e+05   \n",
      "4    7.375940e+04 -1.084992e+07 -380722.666021  5.721812e+06 -9.071929e+04   \n",
      "..            ...           ...            ...           ...           ...   \n",
      "495 -7.117956e+05 -6.505574e+06  331886.743274 -1.378294e+06  7.542409e+05   \n",
      "496  1.451611e+06 -1.103609e+07  -32936.474682 -4.528141e+06 -3.556612e+05   \n",
      "497 -1.382723e+06 -1.217991e+06  383093.834699  5.617075e+04 -5.065342e+02   \n",
      "498  1.000726e+06 -7.433897e+06  422214.251116  4.507125e+06  2.808423e+05   \n",
      "499  7.876548e+05 -6.842811e+06  287602.181774  4.382123e+06  1.082518e+06   \n",
      "\n",
      "         feature5      feature6      feature7      feature8      feature9  \\\n",
      "0   -3.580094e+05  2.253138e+03 -7.051297e+05  5.127805e+06 -1.040817e+06   \n",
      "1    5.792264e+06 -1.138032e+06 -1.538528e+06  4.056611e+06 -5.258557e+06   \n",
      "2    7.641978e+06 -7.966618e+05 -3.137913e+05  1.320932e+06 -5.471899e+06   \n",
      "3   -1.308578e+07  5.491249e+05  1.094025e+05  7.697922e+06  5.829609e+06   \n",
      "4    1.147354e+07  2.923577e+05  1.029069e+06 -5.504916e+06  1.196950e+07   \n",
      "..            ...           ...           ...           ...           ...   \n",
      "495  1.003282e+06  3.310545e+05  1.919032e+06 -5.519955e+05 -7.688568e+06   \n",
      "496 -9.417751e+05 -3.184662e+05  2.783571e+05  5.501970e+06 -5.374570e+06   \n",
      "497  1.043747e+07  7.514554e+05 -8.881023e+05  1.225207e+06  9.152548e+06   \n",
      "498 -1.011333e+07 -5.661898e+04 -1.265185e+05  3.033315e+06 -5.905237e+06   \n",
      "499 -1.112249e+07 -2.307167e+05 -1.666060e+06 -6.324484e+06  1.236748e+07   \n",
      "\n",
      "     site  \n",
      "0       0  \n",
      "1       0  \n",
      "2       0  \n",
      "3       0  \n",
      "4       0  \n",
      "..    ...  \n",
      "495     9  \n",
      "496     9  \n",
      "497     9  \n",
      "498     9  \n",
      "499     9  \n",
      "\n",
      "[500 rows x 11 columns]\n"
     ]
    }
   ],
   "source": [
    "class MLP(nn.Module):\n",
    "    #two input features, 1 hidden layer, one output, use sigmoid to transform the weighted sum of the inputs to non-linear\n",
    "    def __init__(self, input_dim, hidden_dim, output_dim,classification=False):\n",
    "        super(MLP, self).__init__()\n",
    "        #self.layers = nn.ModuleList()\n",
    "        #prev_dim = input_dim\n",
    "        \n",
    "        #for hidden_dim in hidden_dims:\n",
    "        self.hidden_layer = nn.Linear(input_dim, hidden_dim)\n",
    "        nn.init.normal_(self.hidden_layer.weight, mean=0, std=1)  \n",
    "        nn.init.normal_(self.hidden_layer.bias, mean=0, std=1)    \n",
    "       \n",
    "        self.output_layer = nn.Linear(hidden_dim, output_dim)\n",
    "        nn.init.normal_(self.output_layer.weight, mean=0, std=1)  \n",
    "        nn.init.normal_(self.output_layer.bias, mean=0, std=1)    \n",
    "   \n",
    "    def forward(self, x):\n",
    "        #for layer in self.layers:\n",
    "        x = torch.sigmoid(self.hidden_layer(x))  # sigmoid activation function\n",
    "        return self.output_layer(x) #output without activation function\n",
    "\n",
    "\n",
    "def fixed_effect_nonlinear(x):#multi-layer perceptron with logistic activation functions\n",
    "    X_tensor=torch.tensor(x.values,dtype=torch.float32)#comvert datafrmae to numpy\n",
    "    input_dim=2\n",
    "    hidden_dim=1\n",
    "    output_dim=1\n",
    "    model=MLP(input_dim,hidden_dim,output_dim)\n",
    "    model.eval()\n",
    "    y_simulated=model(X_tensor).detach().numpy()\n",
    "    return(y_simulated)\n",
    "# print(len(gamma_ig))\n",
    "#simulate features for all sites when assuming nonlinear for fixed effect\n",
    "phi_G = []  \n",
    "standardized_age1 = np.concatenate(standardized_age)\n",
    "sex1 = np.concatenate(sex)\n",
    "# print(sex1)\n",
    "x = pd.DataFrame({'age': standardized_age1, 'sex': sex1})\n",
    "# print(x.values)\n",
    "\n",
    "for g in range(G):  \n",
    "    d = fixed_effect_nonlinear(x)  \n",
    "    phi_G.append(d)\n",
    "\n",
    "#convert phi to be in the format of for each site\n",
    "phi_I=[]\n",
    "for i in range(I):\n",
    "    d=[]\n",
    "    for g in range(G):\n",
    "        phi_g=phi_G[g]\n",
    "        a=i*n_i\n",
    "        b=(i+1)*n_i\n",
    "        phi_ig=phi_g[a:b]\n",
    "        d.append(phi_ig)\n",
    "    phi_I.append(np.column_stack(d))\n",
    "# print(phi_I[1].shape)   \n",
    "\n",
    "#print(len(phi[0]))\n",
    "data = []\n",
    "for i in range(I):#for each site\n",
    "    J = n_i  # n_i is same for all sites\n",
    "    gamma_i = gamma_IG[i]\n",
    "    delta_i = delta_IG[i]    \n",
    "    x = pd.DataFrame({'age': standardized_age[i], 'sex': sex[i]})  # Ensure age[i] and sex[i] are iterable\n",
    "    phi_i=pd.DataFrame(phi_I[i])\n",
    "    data1 = []\n",
    "    for j in range(J):#for each participant\n",
    "        each_participant = []  # generated features for each participant\n",
    "        x_ij = x.iloc[j, :]\n",
    "\n",
    "        for g in range(G):#for each feature\n",
    "            sigma_g = sigma_G[g]\n",
    "            theta_g = theta_G.iloc[g, :]\n",
    "            epsilon_ijg = stats.norm.rvs(loc=0, scale=sigma_g, size=1)[0]  \n",
    "            phi=phi_i.iloc[j,g]            \n",
    "            y_ijg = alpha_G[g] + phi + gamma_i[g] + delta_i[g] * epsilon_ijg\n",
    "\n",
    "            each_participant.append(y_ijg)\n",
    "\n",
    "        data1.append(each_participant)\n",
    "\n",
    "    data1 = pd.DataFrame(data1, columns=[f'feature{g}' for g in range(G)])\n",
    "    data1['site'] = i\n",
    "    data.append(data1)\n",
    "\n",
    "final_data = pd.concat(data, ignore_index=True)\n",
    "print(final_data)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
